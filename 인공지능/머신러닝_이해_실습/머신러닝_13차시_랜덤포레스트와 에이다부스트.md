## 앙상블 학습의 종류  
  
- 배깅 : 같은 알고리즘을 사용하되 훈련 세트의 서브셋을 무작위로 구성하여 다르게 학습을 시키는 것 
ex) 랜덤 포레스트  
=> 표본데이터-> 약한 모델 -> 강한 모델  
참고) 약한 모델의 정확도가 낮으면 결과가 좋지 않음  
배깅의 장점 : 데이터를 골고루 사용할 수 있다  
머징모델을 통해 좋은 성능의 모델을 만들 수 있음  
- 부스팅(Boosting) : 정확도가 떨어지는 모델에 가중치를 주어서 오류데이터에 대하여 더 세심하게 배려한 모델  
ex) 에이다부스트  
결과 취합 => 모델 성능을 고려한 가중치 투표  
배깅 : 일반 투표  
부스팅 : 가중치 투표  
부스팅 특징  
- 약한 모델에서 더 많은 표본을 가져오게 됨  
- 강한 모델의 결과를 구할 때에도 모델에 따른 가중치에 따라서 취합을 하게 됨  
=> 부스팅은 배깅보다 강력한 모델을 만들 수 있다!  
  
## 랜덤 포레스트와 에이다부스트  
  
### 랜덤 포레스트 => 배깅(부스팅) + 결정 트리를 합한 머징 모델  
  - 분류기에서 인기  
  - 회귀 분석에 응용  
  - 군집 분석에 응용  
랜덤포레스트의 예)  
- 소셜 네트워크의 중심성 지수  
- 회귀 나무 모델  
  
배깅과 부스팅 (랜덤포레스트 포함)은 데이터를 골고루 써서 노이즈에 강함  
학습데이터가 적으면 오버피팅의 가능성이 커짐  
- 오버피팅 : train 데이터에 모델이 심하게 적합되어 테스트 데이터의 정확도가 떨어지는 현상  
  
에이다부스트 : 오류가 난 데이터에 가중치 둠 => 더 많은 리샘플링을 하도록 유도함  
  
경계선 부분에서 애매하게 걸려있는 오류 데이터 : 더 많은 관심을 가지고 집중적으로 훈련을 시키도록 함  
  
결과 취합 시 분류기마다 가중치를 두어서 최종 결과를 반환해야 함  


### 정리)  
배깅:  
- 표본데이터별로 모델을 여러 개 만들어야 함  
- 표본 데이터와 모델은 1:1 매칭  
- 표본데이터는 복원추출이므로 교집합이 존재할 수도 있다  
부스팅:  
- 표본데이터별로 모델을 만든다는 점에서 배깅과 비슷  
- 최종 결과는 배깅과 다르게 가중치 평균이나 가중치 투표를 함  
- 오류가 많이 난 모델의 경우는 가중치에 변화를 주어서 해당하는 오류데이터를 더 많이 수집하도록 함  
랜덤 포레스트의 응용 사례  
- 백화점의 소비패턴을 관찰하여 해당하는 고객의 연령대를 분류하여 예측한다.  
- 최적의 상가 위치를 분석하여 예상되는 매출액을 예측한다  
- 고객의 속성을 보고 화이트데이에 구입할 선물의 종류를 예측한다.  
