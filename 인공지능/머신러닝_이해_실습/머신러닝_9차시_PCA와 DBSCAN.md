## 차원 축소와 주성분 분석(PCA)  
  
고차원을 저차원으로 축소시켜 데이터를 표현하면 설명, 해석에 용이  
  
고차원을 저차원으로 바꾸는 이유 : 고차원에서 일어나는 차원의 저주 문제를 피하기 위함!  
  
ex) 차원축소의 대표적인 방법 : 주성분 분석 (PCA)  
  
PCA란?  
기존 원본 데이터의 정보를 최대한 살리면서 차원이 축소된 새로운 축(좌표 체계)을 다시 설계하는 것  
  
차원 축소 시 정보를 조금 잃는 대신 차원이 축소되는 효과  

PCA 알고리즘 : 새로운 축 w를 기존의 변동을 가장 많이 반영하는 방향으로 잡는 것  

이때 새로운 발견된 차원에 대한 축은 서로 독립이며 직각이어야 한다.

X^T * X = VDV^T, X = UV^T   
X = 원본 데이터  
U = scores 행렬  
V = 부하(loadings) 행렬  
고윳값 분해 사용!!  
D = 대각 행렬  
X^T * X의 고윳값이 내림차순으로 구성 
선형대수 관점)
V = 직교 행렬  
U행렬 : N = 데이터 개수   
V행렬 : P = 원본 차원  
K = 축소된 차원  
  
U와 V를 곱하면 원본데이터 X  
  
중요) P개의 차원을 K개의 차원으로 축소하였다. 정보손실을 최소화하는 K를 골라야 한다!  
  => 정확한 K를 골라주는 여러 가지 방법론이 있다.  
  
* 차원을 축소함으로써 얻는 이득과 잃는 것은?  
고차원을 저차원으로 축소함으로써 모델을 조금이나마 단순화시킬 수 있고 설명력있는 최소한의 속성을 발견할 수 있으며 그것을 feature로 얻어서 다른 모델에 대한 변수로 활용할 수도 있습니다. 대신 축소함으로써
불가피하게 정보를 잃게 된다.  
  
## 밀도기반 군집분석(DBSCAN)  
  
K-means : 길쭉하게 배열된 데이터에 대해 오류가 많음  
DBSCAN : 밀도기반으로 노이즈까지 잡아내는 탁월한 성능을 가진 군집분석  
  
PCA와 DBSCAN을 이용하여 군집분석을 하는 예제 다루기  
: 데이터 압축 -> 거리함수 선정 -> 군집 분석  
  
용어)  
+ 이웃 벡터 : 한 데이터로부터 반경 epsilon의 원 안에 포함된 데이터 벡터(점객체)  
+ 핵심 벡터 : n개 이상의 이웃 벡터를 갖는 데이터 벡터  
+ 직접 접근 가능 : 핵심 벡터 p와 p의 이웃 벡터 q와의 관계 (p->q로 표시)  
+ 접근 가능 : 어떠한 데이터 벡터와 p와 q에 대하여 직접 접근 가능한 p->p1->p2->...->q의 관계가 있다면 q는 p로부터 접근 가능 (p => q로 표시)  
+ 연결 가능 : 데이터 벡터 p와 q 사이에 접근 가능한 데이터 벡터 r이 존재한다면 (r=>p, r=>q) p와 q는 서로 연결되어 있음 (p <=> q로 표시)  
  
군집(Cluster) : 한 핵심 벡터 p에 대하여 접근 가능한 모든 벡터들의 집합  
 => 군집 내의 모든 데이터들은 연결 가능해야 한다!  
노이즈 : 어떠한 군집에도 속하지 않은 데이터  
=> DBSCAN은 노이즈를 명확히 정의 가능하다는 장점 존재!!  
