## 1. 은닉층 기울기  
 [1] 은닉층 뉴런  
  - y_j : 은닉층의 i번째 출력  
  - u_j : j번째 가중치곱과 편향의 합  
  - w_ij : 가중치 (i, j)  
  - y_j : j번째 출력  
  - b_j : j번째 편향  
 Y = [y_1, y_2, y_3, ..., y_i, ..., y_l]  
 W =  
w_11 w_12 ... w_1m  
w_21 w_22 ... w_2m  
w_31 w_32 ... w_3m  
...  
w_l1 w_l2 ... w_lm  
=> l * m 행렬  
  
편향은 모두 m개가 필요  
l개의 입력이 들어온 후, j번째 열에 있는 모든 가중치로 각각 곱해주고 그것을 모두 더한 다음 j번재 편향을 더하고, 그것이 활성화함수를 통과하면 j번재 출력이 된다.  
  
 [2] 가중치 기울기  
  - 오차 E를 가중치 w_ij로 편미분한 d E / d w_ij를 구함    
  - 이렇게 구한 가중치 기울기를 d w_ij라 하면 다음과 같이 표기  
   d w_ij = d E / d w_ij  
  - 위 식을 합성함수 미분법칙을 사용하여 다음과 같이 전개  
   d w_ij = d E / d w_ij = (d E / d u_j) * (d u_j / d w_ij)  
  - 우변 d u_j / d w_ij의 분자 u_j는 입력층에 있는 여러 뉴런의 출력값과 가중치 곱의 합에 편향을 더한 것  
   d u_j / d w_ij = d (sum(from p=1 to l)(y_p * w_pj + b_j)) / d w_ij  
   = d / d w_ij * (y_1*w_1j + y_2*w_2j + ... + y_i*w_ij + y_l*w_lj + b_j)  
   = y_i ---> 출력층의 결과와 동일!  
  - d E / d u_j = (d E / d y_j) * (d y_j / d u_j)  
    이 식의 우변 d y_j / d u_j은 활성화 함수를 미분하여 구할 수 있음  
  - d E / d y_j은 오차에 대한 은닉층의 출력 기울기이며, 이전 출력층에서 구한 d y_j임.  
  delta_j = d E / d u_j = d y_j * (d y_j / d u_j)  
  => delta_j를 구하기 위해 출력층에서 구한 d y_j를 사용, 신경망을 거슬러 올라감  
 - 위의 식들을 대입하여 가중치 기울기 식 완성  
  d w_ij = y_i * delta_j  
  
 [3] 편향 기울기  
  - 오차 E를 가중치 b_j로 편미분만 d E / d b_j를 구함  
  - 이렇게 구한 가중치 기울기를 d b_j라 하면 다음과 같이 표기  
   d b_j = d E / d b_j  
  - 위 식을 합성함수 미분법칙을 사용하여 다음과 같이 전개  
   d b_j = d E / d b_j = (d E / d u_j) * (d u_j / d b_j)  
  - 우변 d u_j / d b_j의 분자는 입력층에 있는 여러 뉴런의 출력값과 가중치 곱의 합에 편향을 더한 것  
   d u_j / d b_j = d(sum(from p=1 to l)(y_p * w_pj + b_j)) / d b_j  
  = d / d b_j * (y_1 * w_1j + y_2 * w_2j + ... + y_i * w_ij + y_l * w_lj + b_j) = 1  
  - 우변의 왼쪽 부분, d E / d u_j은 가중치 기울기의 경우와 마찬가지로 delta_j로 정의  
  - 위 식을 이용하여 편향 기울기를 정리하면 아래와 같음  
   d b_j = delta_j ----> 오차에 대한 편향의 기울기는 delta_j와 동일  
  - 이 층의 앞에 은닉층이 더 있을 경우, d y_j를 구해서 동일한 방법으로 전파  
  - 참고) delta는 은닉층의 뉴런 수인 m개가 존재한다!!  
  
## 2. 기울기 정리  
  
 [1] 출력층 기울기  
  d w_jk = d E / d w_jk  
  d b_k = d E / d b_k  
  d y_j = d E / d y_j  
  delta_k = d E / d u_k = (d E / d y_k) * (d y_k / d u_k)  
  d w_jk = y_j * delta_k  
  d b_k = delta_k  
  d y_j = sum(from r=1 to n)(delta_r * w_jr)  
  - delta_k를 구하는 방법은 손실 함수와 활성화 함수의 조합에 따라 다름  
  - delta_k의 수는 출력층 뉴런의 수와 동일  
   
 [2] 은닉층 기울기  
  d w_ij = d E / d w_ij  
  d b_j = d E / d b_j  
  d y_i = d E / d y_i  
  delta_j = d E / d u_j = (d E / d y_j) * (d y_j / d u_j) = d y_j * (d y_j / d u_j)  
  d w_ij = y_i * delta_j  
  d b_j = delta_j  
  d y_i = sum(from q=1 to m)(delta_q * w_iq)  
  - delta_j를 구하는 방법은 활성화 함수에 따라 다름  
  - delta_j의 수는 은닉층 뉴런의 수와 동일

<img width="498" alt="1" src="https://github.com/user-attachments/assets/a7ccc393-2128-47c4-a3d2-17d4d27411b4" /> <br>
<img width="505" alt="2" src="https://github.com/user-attachments/assets/e7d21856-adef-4f18-9646-3bca3ac00128" /> <br>
<img width="441" alt="3" src="https://github.com/user-attachments/assets/53eb9761-8d13-48c8-ba27-2a497e5adfee" /> <br>
<img width="405" alt="4" src="https://github.com/user-attachments/assets/2a6fcc16-4320-4f18-a72c-f4236b8a88a3" /> <br>
<img width="419" alt="5" src="https://github.com/user-attachments/assets/6cc22d31-1add-4997-bc59-2ccab5e9d2b9" /> <br>




