{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnssZ6f1YcLOFzm7sYI6/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Song-Hyunsub/Univ_Study/blob/main/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_6%EC%B0%A8%EC%8B%9C_%EC%97%AD%EC%A0%84%ED%8C%8C_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 훈련 및 테스트용 데이터 분리  \n",
        "\n",
        "[1] 훈련 데이터와 테스트 데이터  \n",
        " - 훈련 데이터 : 신경망이 학습에 이용하는 데이터  \n",
        " - 테스트 데이터 : 학습결과의 검증에 사용하는 데이터  \n",
        " - 각 데이터는 여러 개의 입력값(Feature)과 정답(Target)으로 구성됨  \n",
        " - 입력값과 정답의 한 쌍을 \"샘플\"이라 함!  \n",
        " - 훈련 데이터의 샘플수 > 테스트 데이터의 샘플 수  \n",
        " - 훈련 데이터로 학습이 잘 된 신경망의 경우, 테스트 데이터에서 좋은 결과가 나옴 => 모델이 일반화가 잘 되었다고 함  \n",
        "  \n",
        "## 2. 손실함수의 종류 및 내용  \n",
        "\n",
        "[1] 오차(손실)  \n",
        " - 회귀문제의 정답과 출력  \n",
        "  + 은닉, 출력층을 거쳐 나온 최종 출력과 정답은 차이가 날 수 있다.  \n",
        "  + 출력과 정답의 간격을 오차라고 함 => 하나의 값  \n",
        " - 분류문제의 정답과 출력  \n",
        "  + 은닉, 출력층을 거쳐 나온 최종 출력과 정답이 여러 쌍이 있다.  \n",
        "  + 이때, 출력된 모든 확률을 더하면 1이 나와야 함!  \n",
        "  + 정답이 아닌 항목은 0, 정답인 항목은 1로 두어서 분류해야할 가짓수만큼 0과 1로 분류하는데, 이것을 One-Hot encoding이라고 한다.  \n",
        "  \n",
        "[2] 평균제곱오차 : MSE(Mean Squared Error)  ( => 회귀용 손실 함수)\n",
        "  E = 1/n * sum(from k=1 to n) (y_k - t_k)^2  \n",
        "  - n: 배치사이즈  \n",
        "  - y_k : k번째 출력  \n",
        "  - t_k : k번째 정답  \n",
        "  Code)  \n",
        "\timport numpy as np  \n",
        "\tdef mean_squared_error(y, t):  \n",
        "\t\treturn np.sum(np.power(y-t, 2)) / y.shape[0]  \n",
        "  \n",
        "[3] 오차제곱합 : SSE(Sum of Squares for Error)  ( => 회귀용 손실 함수)\n",
        " E = 1/2 * sum(from k=1 to n) (y_k - t_k)^2  \n",
        " Code)  \n",
        " import numpy as np  \n",
        " def square_sum(y, t):  \n",
        "\treturn 1.0/2.0 * np.sum(np.square(y-t))  \n",
        "   \n",
        "[4] 교차 엔트로피  ( => 분류용 손실 함수)\n",
        " E = - sum(from k=1 to n) (t_k * log y_k)  \n",
        "  => E = sum(from k=1 to n)(t_k * (-log y_k))  \n",
        "  + 분류문제의 정답은 1이 하나이고 나머지는 모두 0인 One-Hot encoding 벡터  \n",
        "  + 시그마(sum) 내부에서 k번째 항목인 t_k가 1인 항에 대해서 결과가 나옴\n",
        "  + 결국 오차는 y=-log(x) 형태를 취함  \n",
        "  + x를 t_k로 보면 1일 경우 0  \n",
        "  + x가 0에 근접할수록 무한대로 발산  \n",
        "  + t_k가 1에 근접할수록 오차가 작아짐  \n",
        "  + 실제에서는 log함수의 진수 부분이 0이 되면 무한 발산하여 계산이 불가능함 => 이를 방지하기 위해 1e-7을 더함  \n",
        " Code)  \n",
        " import numpy as np  \n",
        " def cross_entropy(y, t): # 출력, 정답  \n",
        " \treturn - np.sum(t * np.log(y + 1e-7))  \n",
        "  \n",
        "## 3. 경사하강법의 개념  \n",
        "  \n",
        "[1] 기본 아이디어  \n",
        " - 정답과 출력간의 오차는 오차함수를 이용해 구함 => 이렇게 구한 오차는 각 층마다 계산에 투입된 가중치와 편향들의 함수로 볼 수 있음  \n",
        " - 특정 가중치 w_ij와 오차 E와의 함수 관계가 다음과 같다고 가정함  \n",
        "omega <- omega - eta * (d E / d omega)  \n",
        "b <- b - eta * (d E / d b)  \n",
        "eta : 학습률 (learning rate)  \n",
        " + 그래프 꼭 참고하기!!  \n",
        "전역 최적해 => 함수 전체의 최솟값  \n",
        "기울기가 0이 되는 부분 중 전역 최적해가 아닌 곳 => 국소 최적해  \n",
        "오차를 해당 편향으로 편미분 => 원래 값에서 빼줌  \n",
        "=> 양수일 때는 양수를 빼면 값이 작아져서 0에 가까워지고, 음수일때는 음수를 빼기 때문에 값이 커져서 0에 가까워짐  \n",
        "보폭을 너무 크게 잡으면 국소 최적해에 빠지게 됨!  \n",
        "w_ij 축에서 갱신하는 보폭을 eta : 학습률이라고 함  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1pkG-Y3O_VXI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jR7ZE6jX375I"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.array([20, 25, 27, 26, 28])\n",
        "y = np.array([19.5, 24.2, 26.1, 25.7, 29.3])"
      ],
      "metadata": {
        "id": "3Uefp-DO4bXX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE 구하기\n",
        "def mean_squared_error(y, t):\n",
        "  return np.sum(np.power(y-t, 2)) / y.shape[0]"
      ],
      "metadata": {
        "id": "qZK1fK4P4nHj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = mean_squared_error(y, t)"
      ],
      "metadata": {
        "id": "wR5DUA0h4u_D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_2TckS-4yV1",
        "outputId": "c14c05f8-eb07-4d41-a7be-b47be9eb5108"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6960000000000002"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SSE 구하기\n",
        "def square_sum(y, t):\n",
        "  return 1.0 / 2.0 * np.sum(np.square(y-t))"
      ],
      "metadata": {
        "id": "S85ATCOf4zgB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = square_sum(y, t)"
      ],
      "metadata": {
        "id": "XA85Q05H47bd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpBo2txi5CAC",
        "outputId": "f518e518-6025-4129-9276-ad62f0081aca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7400000000000004"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.array([0, 0, 1, 0, 0])\n",
        "y = np.array([0.1, 0.1, 0.7, 0.05, 0.05])"
      ],
      "metadata": {
        "id": "7aTWVO_R7hZR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 교차 엔트로피 구하기\n",
        "def cross_entropy(y, t):\n",
        "    return - np.sum(t * np.log(y + 1e-7))"
      ],
      "metadata": {
        "id": "_NbZ-1Mf7pY0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = cross_entropy(y, t)"
      ],
      "metadata": {
        "id": "C9t9NOlX7wQg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4LrFSNo7zTg",
        "outputId": "74bbdc77-77cf-4ad1-b1f7-52e4747f04e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3566748010815999"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}