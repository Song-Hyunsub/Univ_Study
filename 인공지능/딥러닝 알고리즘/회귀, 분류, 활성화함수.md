## 회귀 : 데이터의 추세 표현  
- 연속적인 수치 예측
- 키와 몸무게의 관계, 주가 예측, 인구 성장 추이  
## 분류 : 데이터를 정해진 범주에 따라 분류  
- 주어진 데이터를 미리 정해 둔 레이블에 따라 분류
- 개와 고양이 이미지 분류, 주제에 따른 기사 분류 등
- 
## 활성화 함수

활성화 함수는 **인공 뉴런의 입력을 출력으로 변환**하는 함수로, 인공 뉴런의 계산 결과값(선형 결과)을 **비선형 출력**으로 변환하기 위해 사용됩니다. 주요 활성화 함수와 그 특성은 다음과 같습니다:

---

### 1. **Sigmoid**
- 가장 대표적인 활성화 함수
- 수식:  
  \[
  y = \frac{1}{1 + e^{-x}}
  \]
- **출력 범위**: \(0 \sim 1\)

---

### 2. **Tanh (Hyperbolic Tangent)**
- 수식:  
  \[
  y = \frac{e^x - e^{-x}}{e^x + e^{-x}}
  \]
- **출력 범위**: \(-1 \sim 1\)

---

### 3. **ReLU (Rectified Linear Unit)**
- 정의:  
  \[
  y = 
  \begin{cases} 
  0 & \text{if } x \leq 0 \\ 
  x & \text{if } x > 0 
  \end{cases}
  \]
- **특성**: 음수에 대한 출력 \(y = 0\)

---

### 4. **Leaky ReLU**
- 정의:  
  \[
  y = 
  \begin{cases} 
  0.01x & \text{if } x \leq 0 \\ 
  x & \text{if } x > 0 
  \end{cases}
  \]
- **특성**: \(x \leq 0\)인 영역에 **작은 기울기** 생성

---

### 5. **Softmax**
- 정의:  
  \[
  f(\vec{x})_i = \frac{e^{x_i}}{\sum_{k=1}^n e^{x_k}}
  \]
  (\(i\)는 자연수, \(k\)는 합산 인덱스)
- **특성**:  
  - 각 입력을 \(0 \sim 1\) 값으로 **정규화**  
  - **출력 값의 총합**: \(1\)

---

이와 같은 활성화 함수들은 모델의 학습과 성능에 중요한 역할을 합니다.
