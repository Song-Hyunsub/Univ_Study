# CS246: Mining Massive Data Sets (번역본)

## 1. 데이터에는 가치와 지식이 포함되어 있습니다
- 하지만 지식을 추출하기 위해서는 데이터가:
  - **저장**되어야 하고 (시스템)
  - **관리**되어야 하며 (데이터베이스)
  - **분석**되어야 합니다. 이 수업에서는 이 부분을 다룹니다.

## 2. 데이터 마이닝이란 무엇인가?
- 데이터 마이닝 ≈ 빅 데이터 ≈ 예측 분석 ≈ 데이터 과학 ≈ 머신 러닝
- 데이터 마이닝은 일반적으로 매우 큰 데이터 세트에서 실행 가능한 정보를 추출하는 과정으로, 이는 많은 관심과 두려움을 불러일으킵니다.
- 데이터 마이닝은 전부 머신 러닝에 관한 것은 아니지만, 대부분의 경우 머신 러닝이 중요합니다.
- 이 수업에서는 확장 가능한 알고리즘에 중점을 둡니다. 병렬화가 종종 필수적입니다.

## 3. 데이터 마이닝의 방법론
- **설명적 방법론**:
  - 데이터에서 사람의 해석이 가능한 패턴을 찾아냅니다.
  - 예: 클러스터링
- **예측적 방법론**:
  - 어떤 변수들을 사용하여 다른 변수들의 미지의 값이나 미래의 값을 예측합니다.
  - 예: 추천 시스템

## 4. 데이터 마이닝과 관련된 다양한 학문 분야
- 이 과정은 머신 러닝, 통계, 인공지능, 데이터베이스 시스템의 최선의 요소들을 결합합니다. 그러나 이 과정에서는 특히 **확장성(빅 데이터)**, **알고리즘**, **컴퓨팅 아키텍처**, 그리고 대규모 데이터를 다루기 위한 **자동화**에 중점을 둡니다.

## 5. 수업에서 다룰 데이터 유형
- 이 수업에서는 다양한 유형의 데이터를 마이닝하는 법을 배웁니다:
  - **고차원 데이터**
  - **그래프 데이터**
  - **무한/끊임없는 데이터**
  - **레이블이 지정된 데이터**

## 6. 수업에서 사용할 계산 모델
- 이 수업에서는 다양한 계산 모델을 배웁니다:
  - **MapReduce**
  - **스트림 및 온라인 알고리즘**
  - **단일 머신 메모리 내 계산**

## 7. 실전 문제 해결
- 이 수업에서는 실제 문제를 해결하는 방법을 배웁니다:
  - **추천 시스템**
  - **장바구니 분석 (Market Basket Analysis)**
  - **스팸 탐지**
  - **중복 문서 탐지**

## 8. 다양한 도구 사용법
- 이 수업에서는 다양한 도구를 사용합니다:
  - **선형 대수학** (예: SVD, 추천 시스템, 커뮤니티 탐색)
  - **최적화** (예: 확률적 경사 하강법)
  - **동적 프로그래밍** (예: 빈발 항목 집합 탐색)
  - **해싱** (예: LSH, 블룸 필터)

## 9. 대규모 컴퓨팅
- 대규모 데이터 마이닝 문제를 해결하기 위해서는 대규모 컴퓨팅이 필수적입니다.
- 주요 도전 과제:
  - **계산 작업의 분배 방법**
  - **분산 프로그램을 쉽게 작성하는 방법**
  - **머신의 실패 대처 방법**
    - 예를 들어, 하나의 서버가 3년 동안 (1,000일) 정상 작동할 수 있지만, 1,000대의 서버가 있다면 매일 1대의 서버가 고장날 확률이 있습니다.
    - 100만 대의 머신이 있다면 매일 1,000대의 머신이 고장날 가능성이 있습니다.

## 10. 네트워크에서의 데이터 전송 문제
- 데이터 전송은 시간이 걸립니다. 해결책으로는 **계산을 데이터로 가져오는 것**이 있습니다. 데이터의 신뢰성을 위해 파일을 여러 번 저장할 수 있습니다.
- Spark와 Hadoop이 이러한 문제를 해결합니다:
  - **저장 인프라**: 파일 시스템 (예: Google의 GFS, Hadoop의 HDFS)
  - **프로그래밍 모델**: MapReduce, Spark

## 11. 분산 파일 시스템
- 문제: 노드가 실패하면 데이터를 어떻게 지속적으로 저장할 것인가?
- 해답: **분산 파일 시스템**을 사용하여 전역 파일 네임스페이스를 제공합니다.
- 일반적인 사용 패턴:
  - 대규모 파일 (100GB에서 수 TB)이 생성됩니다.
  - 데이터는 드물게 제자리에 업데이트되며, 읽기와 추가가 일반적입니다.

## 12. MapReduce의 개요
- **MapReduce**는 병렬 프로그래밍을 쉽게 하고, 하드웨어 및 소프트웨어의 실패를 투명하게 관리하며, 대규모 데이터를 쉽게 관리할 수 있도록 설계된 프로그래밍 방식입니다.
- 여러 구현체가 있습니다: Hadoop, Spark (이 수업에서 사용), Flink, 그리고 Google의 초기 MapReduce 구현체.

## 13. MapReduce 작업의 예
- 예를 들어, 매우 큰 텍스트 문서가 있고 각 단어가 몇 번 나타나는지 세어야 합니다.
- 많은 응용 프로그램에서 이를 사용할 수 있습니다:
  - 웹 서버 로그를 분석하여 인기 있는 URL을 찾습니다.
  - 통계적 기계 번역에서는 문서에 나타나는 5단어 시퀀스의 개수를 세어야 합니다.

## 14. MapReduce의 장단점
- **장점**:
  - 순차적 데이터 접근이 필요한 문제에 적합합니다.
  - 대규모 배치 작업에 적합합니다.
- **단점**:
  - 그래프, 상호 의존 데이터, 머신 러닝, 많은 항목 쌍의 비교와 같은 불규칙한 데이터 접근이 필요한 문제에는 비효율적입니다.

## 15. Spark와 MapReduce 비교
- **성능**: Spark는 일반적으로 더 빠르지만, 메모리 사용량이 많습니다. 반면, MapReduce는 디스크에 결과를 저장하기 때문에 자원 사용에 덜 민감합니다.
- **사용의 용이성**: Spark는 더 높은 수준의 API를 제공하여 프로그래밍이 더 쉽습니다.
- **데이터 처리**: Spark는 더 일반적인 데이터 처리 시스템을 제공합니다.

## 16. 분산 시스템에서의 비용 분석
- 알고리즘의 비용을 통신 비용과 계산 비용으로 나눌 수 있습니다.
- **통신 비용**: 입력 파일 크기와 맵-리듀스 프로세스 사이의 모든 파일 크기 합계 및 리듀스 프로세스 출력 크기 합계로 계산됩니다.
- **계산 비용**: 입력 및 출력 크기에 비례합니다.
